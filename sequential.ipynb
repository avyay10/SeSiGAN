{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import img_to_array\nimport os\nfrom tqdm import tqdm\nimport re\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-04T06:28:28.45015Z","iopub.execute_input":"2021-11-04T06:28:28.450834Z","iopub.status.idle":"2021-11-04T06:28:34.239943Z","shell.execute_reply.started":"2021-11-04T06:28:28.450726Z","shell.execute_reply":"2021-11-04T06:28:34.239015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to get the files in proper order\ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)\n# defining the size of the image\nSIZE = 256\nhigh_img = []\npath = '../input/image-super-resolution/dataset/Raw Data/high_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '855.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '/'+i,1)\n        # open cv reads images in BGR format so we have to convert it to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') / 255.0\n        high_img.append(img_to_array(img))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:34.242132Z","iopub.execute_input":"2021-11-04T06:28:34.242426Z","iopub.status.idle":"2021-11-04T06:28:43.865273Z","shell.execute_reply.started":"2021-11-04T06:28:34.242391Z","shell.execute_reply":"2021-11-04T06:28:43.864342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nlow_img = []\npath = '../input/image-super-resolution/dataset/Raw Data/low_res'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n     if i == '855.jpg':\n        break\n     else: \n        img = cv2.imread(path + '/'+i,1)\n\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') / 255.0\n        low_img.append(img_to_array(img))","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:43.866783Z","iopub.execute_input":"2021-11-04T06:28:43.867129Z","iopub.status.idle":"2021-11-04T06:28:52.636516Z","shell.execute_reply.started":"2021-11-04T06:28:43.867097Z","shell.execute_reply":"2021-11-04T06:28:52.635515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(4):\n    a = np.random.randint(0,855)\n    plt.figure(figsize=(10,10))\n    plt.subplot(1,2,1)\n    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n    plt.imshow(high_img[a])\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n    plt.imshow(low_img[a])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:52.638357Z","iopub.execute_input":"2021-11-04T06:28:52.63876Z","iopub.status.idle":"2021-11-04T06:28:53.685548Z","shell.execute_reply.started":"2021-11-04T06:28:52.638713Z","shell.execute_reply":"2021-11-04T06:28:53.684548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_high_image = high_img[:700]\ntrain_low_image = low_img[:700]\ntrain_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\ntrain_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n\nvalidation_high_image = high_img[700:830]\nvalidation_low_image = low_img[700:830]\nvalidation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\nvalidation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n\n\ntest_high_image = high_img[830:]\ntest_low_image = low_img[830:]\ntest_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\ntest_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n\nprint(\"Shape of training images:\",train_high_image.shape)\nprint(\"Shape of test images:\",test_high_image.shape)\nprint(\"Shape of validation images:\",validation_high_image.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:53.688406Z","iopub.execute_input":"2021-11-04T06:28:53.688739Z","iopub.status.idle":"2021-11-04T06:28:54.555068Z","shell.execute_reply.started":"2021-11-04T06:28:53.688705Z","shell.execute_reply":"2021-11-04T06:28:54.554058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import layers\ndef down(filters , kernel_size, apply_batch_normalization = True):\n    downsample = tf.keras.models.Sequential()\n    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n    if apply_batch_normalization:\n        downsample.add(layers.BatchNormalization())\n    downsample.add(keras.layers.LeakyReLU())\n    return downsample\n\n\ndef up(filters, kernel_size, dropout = False):\n    upsample = tf.keras.models.Sequential()\n    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n    if dropout:\n        upsample.dropout(0.2)\n    upsample.add(keras.layers.LeakyReLU())\n    return upsample\n\ndef model():\n    inputs = layers.Input(shape= [SIZE,SIZE,3])\n    d1 = down(128,(3,3),False)(inputs)\n    d2 = down(128,(3,3),False)(d1)\n    d3 = down(256,(3,3),True)(d2)\n    d4 = down(512,(3,3),True)(d3)\n    \n    d5 = down(512,(3,3),True)(d4)\n    #upsampling\n    u1 = up(512,(3,3),False)(d5)\n    u1 = layers.concatenate([u1,d4])\n    u2 = up(256,(3,3),False)(u1)\n    u2 = layers.concatenate([u2,d3])\n    u3 = up(128,(3,3),False)(u2)\n    u3 = layers.concatenate([u3,d2])\n    u4 = up(128,(3,3),False)(u3)\n    u4 = layers.concatenate([u4,d1])\n    u5 = up(3,(3,3),False)(u4)\n    u5 = layers.concatenate([u5,inputs])\n    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n    return tf.keras.Model(inputs=inputs, outputs=output)\n\nmodel = model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:54.556567Z","iopub.execute_input":"2021-11-04T06:28:54.556884Z","iopub.status.idle":"2021-11-04T06:28:55.077608Z","shell.execute_reply.started":"2021-11-04T06:28:54.556839Z","shell.execute_reply":"2021-11-04T06:28:55.07669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n              metrics = ['acc'])","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:55.07918Z","iopub.execute_input":"2021-11-04T06:28:55.079477Z","iopub.status.idle":"2021-11-04T06:28:55.097452Z","shell.execute_reply.started":"2021-11-04T06:28:55.079447Z","shell.execute_reply":"2021-11-04T06:28:55.096464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,\n          validation_data = (validation_low_image,validation_high_image))","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:28:55.09911Z","iopub.execute_input":"2021-11-04T06:28:55.099419Z","iopub.status.idle":"2021-11-04T06:58:07.321695Z","shell.execute_reply.started":"2021-11-04T06:28:55.099379Z","shell.execute_reply":"2021-11-04T06:58:07.320939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(high,low,predicted):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('High Image', color = 'green', fontsize = 20)\n    plt.imshow(high)\n    plt.subplot(1,3,2)\n    plt.title('Low Image ', color = 'black', fontsize = 20)\n    plt.imshow(low)\n    plt.subplot(1,3,3)\n    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n    plt.imshow(predicted)\n   \n    plt.show()\n\nfor i in range(1,10):\n    \n    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n    plot_images(test_high_image[i],test_low_image[i],predicted)","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:58:07.324918Z","iopub.execute_input":"2021-11-04T06:58:07.325238Z","iopub.status.idle":"2021-11-04T06:58:13.699938Z","shell.execute_reply.started":"2021-11-04T06:58:07.325206Z","shell.execute_reply":"2021-11-04T06:58:13.698897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"final_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-11-04T06:58:32.825376Z","iopub.execute_input":"2021-11-04T06:58:32.825751Z","iopub.status.idle":"2021-11-04T06:58:33.165238Z","shell.execute_reply.started":"2021-11-04T06:58:32.82572Z","shell.execute_reply":"2021-11-04T06:58:33.1644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
